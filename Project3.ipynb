{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Implementation Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and read in Project.dd as binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the binary data from the disk dump file for analysis.\n",
    "with open('Project-3/disk-drives/Project3.dd', 'rb') as disk_image:\n",
    "    data = disk_image.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Hexdump Output for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hexdump output has been saved to 'hexdump_output.txt'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to generate a Hexdump style output from the dd file binary data.\n",
    "def hexdump(data, width=16):\n",
    "\n",
    "    # Split the data into lines of the specified width\n",
    "    lines = []\n",
    "\n",
    "    # Loop through the data and format it into hex and ASCII parts, iterating by width.\n",
    "    # Output should look like the hexdumps in the linux machine, with ascii representation on the right.\n",
    "    for i in range(0, len(data), width):\n",
    "\n",
    "        # We iterate through the data 16 bytes at a time, from 0 to the end of the data.\n",
    "        chunk = data[i:i+width]\n",
    "\n",
    "        # Specifies each byte to be represented in 2-digit uppercase hex format, for each byte in the chunk.\n",
    "        hex_part = ' '.join(f'{byte:02X}' for byte in chunk)\n",
    "\n",
    "        # Specifies the ASCII representation of the bytes in the chunk.\n",
    "        ascii_part = ''.join(chr(byte) if 32 <= byte < 127 else '.' for byte in chunk)\n",
    "\n",
    "        # Append the hex and ASCII parts to the lines list, beginning with the 8 byte offset.\n",
    "        lines.append(f\"{i:08X}  {hex_part:<{width * 3}}  {ascii_part}\")\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# Generate the hexdump string (if needed).\n",
    "hexdump_string = hexdump(data)\n",
    "\n",
    "# Write the hexdump to a text file\n",
    "with open('Project-3/Outputs/hexdump_output.txt', 'w') as output_file:\n",
    "    output_file.write(hexdump_string)\n",
    "print(\"Hexdump output has been saved to 'hexdump_output.txt'.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for and Find File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a located directory entry is likely valid based on ASCII name and extension.\n",
    "def is_likely_directory_entry(entry):\n",
    "\n",
    "    # Split the entry into name and extension parts, each 8 and 3 bytes long respectively.\n",
    "    name_part = entry[:8]\n",
    "    ext_part = entry[8:11]\n",
    "    \n",
    "    # Ensure name and extension are ASCII and non-empty, based on the ASCII values.\n",
    "    if not all(32 <= byte < 127 for byte in name_part + ext_part):\n",
    "        return False\n",
    "    \n",
    "    # Check if the extension is one of the known types\n",
    "    if ext_part not in common_extensions:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to find directory entries in the disk image data\n",
    "def find_directory_entries(data):\n",
    "\n",
    "    # Create a dictionary to store the file names based on extension types.\n",
    "    files = {}\n",
    "\n",
    "    # Scan through data to find potential directory entries, in 32 byte increments.\n",
    "    for i in range(0, len(data) - 32, 32): \n",
    "        # Each entry being parsed is 32 bytes long.\n",
    "        entry = data[i:i + 32]\n",
    "\n",
    "        # Check if the entry is likely a directory entry based on the ASCII name and extension.\n",
    "        if is_likely_directory_entry(entry):\n",
    "\n",
    "            # Extract the file name and extension from the entry, and store in the dictionary.\n",
    "            # Ignore any encoding errors and strip any whitespace.\n",
    "            file_name = entry[:8].decode('ascii', errors='ignore').strip()\n",
    "            file_ext = entry[8:11].decode('ascii', errors='ignore').strip()\n",
    "\n",
    "            # Store the file name in the dictionary based on the extension.\n",
    "            files[file_ext] = file_name\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "# Define the file extensions we are looking for, represented in bytes.\n",
    "# This will be used to validate the directory entries found in the disk image.\n",
    "common_extensions = [b'JPG', b'PNG', b'GIF', b'AVI', b'PDF']\n",
    "\n",
    "# Find the directory entries in the disk image data, and populate a dictionary with the file names.\n",
    "file_names = find_directory_entries(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define File Signatures, and Trailers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file signatures for the files to be recovered.\n",
    "file_signatures = {\n",
    "    'PDF': b'%PDF',\n",
    "    'GIF': b'GIF89a', # GIF87a not found, so using GIF89a.\n",
    "    'JPG': b'\\xFF\\xD8', # Already in Hex.\n",
    "    'AVI': b'RIFF', \n",
    "    'PNG': b'\\x89PNG\\r\\n\\x1a\\n',\n",
    "    \n",
    "}\n",
    "\n",
    "# Define the end of file signatures for the files to be recovered.\n",
    "file_end = {\n",
    "    'PDF': b'%%EOF',\n",
    "    'GIF': b'\\x00\\x3B', \n",
    "    'JPG': b'\\xFF\\xD9',\n",
    "    'AVI': b'', # AVI files are based on size, so no end signature.\n",
    "    'PNG': b'IEND',\n",
    "}\n",
    "\n",
    "# list to store the names of the files recovered.\n",
    "files = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate and Recover the files based on signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for file signature 'PDF'...\n",
      "File signature 'PDF' found at offset 1370112.\n",
      "End of file signature 'PDF' found at offset 1511728.\n",
      "File 'TAX.pdf' has been saved.\n",
      "\n",
      "Searching for file signature 'GIF'...\n",
      "File signature 'GIF' found at offset 1040384.\n",
      "End of file signature 'GIF' found at offset 1078392.\n",
      "File 'MINION.gif' has been saved.\n",
      "\n",
      "Searching for file signature 'JPG'...\n",
      "File signature 'JPG' found at offset 53248.\n",
      "End of file signature 'JPG' found at offset 65621.\n",
      "File 'AUBURN.jpg' has been saved.\n",
      "\n",
      "Searching for file signature 'AVI'...\n",
      "File signature 'AVI' found at offset 296960.\n",
      "AVI file size (from header): 742470 bytes.\n",
      "End of file calculated at offset 1039438.\n",
      "File 'EARTH.avi' has been saved.\n",
      "\n",
      "Searching for file signature 'PNG'...\n",
      "File signature 'PNG' found at offset 67584.\n",
      "End of file signature 'PNG' found at offset 295543.\n",
      "File 'DICE.png' has been saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through the file signatures and find the files in the data.\n",
    "for sig_name, sig_bytes in file_signatures.items():\n",
    "\n",
    "    print(f\"Searching for file signature '{sig_name}'...\")\n",
    "    \n",
    "    # Find the file signature in the data\n",
    "    start = data.find(sig_bytes)\n",
    "\n",
    "    # If the signature is not found, print a message and continue to the next signature.\n",
    "    if start == -1:\n",
    "        print(f\"File signature '{sig_name}' not found.\")\n",
    "    else:\n",
    "        print(f\"File signature '{sig_name}' found at offset {start}.\")\n",
    "        \n",
    "        # Default the end of the file to -1, in case it is not found.\n",
    "        end = -1\n",
    "\n",
    "        # If the file is an AVI file, calculate the end based on the size in the header.\n",
    "        if sig_name == 'AVI':\n",
    "\n",
    "            # Offset for the 4-byte size located after \"RIFF\".\n",
    "            size_offset = start + 4  \n",
    "            avi_size_bytes = data[size_offset:size_offset + 4]\n",
    "            avi_size = int.from_bytes(avi_size_bytes, byteorder='little')\n",
    "\n",
    "            # Calculate the end of the AVI file based on this size.\n",
    "            # Add 8 for the \"RIFF\" and size fields.\n",
    "            end = start + avi_size + 8  \n",
    "\n",
    "            print(f\"AVI file size (from header): {avi_size} bytes.\")\n",
    "            print(f\"End of file calculated at offset {end}.\")\n",
    "        else:\n",
    "\n",
    "            # Find the end of the file signature in the data, if not an AVI file.\n",
    "            if file_end[sig_name]:\n",
    "\n",
    "                # Locate the end of the file signature in the data following the file signature.\n",
    "                end = data.find(file_end[sig_name], start)\n",
    "\n",
    "                # If the end of the file signature is found, update the end offset to encapsulate the file.\n",
    "                end += len(file_end[sig_name])\n",
    "                print(f\"End of file signature '{sig_name}' found at offset {end}.\")\n",
    "        \n",
    "            else:\n",
    "                print(f\"End of file signature '{sig_name}' not found.\")\n",
    "                continue\n",
    "\n",
    "        # Write the file to a new file, add the name to the files list.\n",
    "        with open(f'Project-3/recovered-files/{file_names[sig_name]}.{sig_name.lower()}', 'wb') as output_file:\n",
    "            output_file.write(data[start:end])\n",
    "        files.append(f'{file_names[sig_name]}.{sig_name.lower()}')\n",
    "\n",
    "\n",
    "        print(f\"File '{file_names[sig_name]}.{sig_name.lower()}' has been saved.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAX.pdf: ebce68e684aef07612374ceb29b529b37a3e8d99b42a899036336bb772d94181\n",
      "MINION.gif: 51e19cb58b5d92fbf793441041dfabda5becfa8f939c982c68517300c5cb39b3\n",
      "AUBURN.jpg: 59e0ec78f30c50db44d24a413ca1cccbd7ef5910cad4d3cf0e4753095725ec94\n",
      "EARTH.avi: 7c1d478794e328ec1d2426b48c6115cb1c364fdfcaa65afcc8dd9cd4301121d2\n",
      "DICE.png: 605256d0b3dcdede81ace571bddbf42572cfba1d68b5f07060c570c1fd537f1d\n"
     ]
    }
   ],
   "source": [
    "# Library needed for hashing the files.\n",
    "import hashlib\n",
    "\n",
    "# Function to generate a SHA-256 hash for a file\n",
    "def generate_sha256_hash(file_path):\n",
    "\n",
    "    # Create a SHA-256 hash object\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    \n",
    "    # Open the file in binary mode (rb) and read in chunks\n",
    "    with open(file_path, 'rb') as file:\n",
    "        for chunk in iter(lambda: file.read(4096), b\"\"):  \n",
    "            sha256_hash.update(chunk)\n",
    "    \n",
    "    # Return the hexadecimal digest of the hash\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "# Generate SHA-256 hashes for the recovered files.\n",
    "hashes = {}\n",
    "for name in files:\n",
    "    file_path = f'Project-3/recovered-files/{name}'\n",
    "    hash_value = generate_sha256_hash(file_path)\n",
    "    hashes[name] = hash_value\n",
    "    print(f\"{name}: {hash_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
