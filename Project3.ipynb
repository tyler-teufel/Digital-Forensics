{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Implementation Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and read in Project.dd as binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the binary data from the disk dump file for analysis.\n",
    "with open('Project-3/disk-drives/Project3.dd', 'rb') as disk_image:\n",
    "    data = disk_image.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Hexdump Output for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a Hexdump style output from the dd file binary data.\n",
    "def hexdump(data, width=16):\n",
    "\n",
    "    # Split the data into lines of the specified width\n",
    "    lines = []\n",
    "\n",
    "    # Loop through the data and format it into hex and ASCII parts, iterating by width.\n",
    "    # Output should look like the hexdumps in the linux machine, with ascii representation on the right.\n",
    "    for i in range(0, len(data), width):\n",
    "\n",
    "        # We iterate through the data 16 bytes at a time, from 0 to the end of the data.\n",
    "        chunk = data[i:i+width]\n",
    "\n",
    "        # Specifies each byte to be represented in 2-digit uppercase hex format, for each byte in the chunk.\n",
    "        hex_part = ' '.join(f'{byte:02X}' for byte in chunk)\n",
    "\n",
    "        # Specifies the ASCII representation of the bytes in the chunk.\n",
    "        ascii_part = ''.join(chr(byte) if 32 <= byte < 127 else '.' for byte in chunk)\n",
    "\n",
    "        # Append the hex and ASCII parts to the lines list, beginning with the 8 byte offset.\n",
    "        lines.append(f\"{i:08X}  {hex_part:<{width * 3}}  {ascii_part}\")\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "# Generate the hexdump string (if needed).\n",
    "hexdump_string = hexdump(data)\n",
    "\n",
    "# Write the hexdump to a text file\n",
    "with open('Project-3/Outputs/hexdump_output.txt', 'w') as output_file:\n",
    "    output_file.write(hexdump_string)\n",
    "print(\"Hexdump output has been saved to 'hexdump_output.txt'.\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for and Find File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a located directory entry is likely valid based on ASCII name and extension.\n",
    "def is_likely_directory_entry(entry):\n",
    "\n",
    "    # Split the entry into name and extension parts, each 8 and 3 bytes long respectively.\n",
    "    name_part = entry[:8]\n",
    "    ext_part = entry[8:11]\n",
    "    \n",
    "    # Ensure name and extension are ASCII and non-empty, based on the ASCII values.\n",
    "    if not all(32 <= byte < 127 for byte in name_part + ext_part):\n",
    "        return False\n",
    "    \n",
    "    # Check if the extension is one of the known types\n",
    "    if ext_part not in common_extensions:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Function to find directory entries in the disk image data\n",
    "def find_directory_entries(data):\n",
    "\n",
    "    # Create a dictionary to store the file names based on extension types.\n",
    "    files = {}\n",
    "\n",
    "    # Scan through data to find potential directory entries, in 32 byte increments.\n",
    "    for i in range(0, len(data) - 32, 32): \n",
    "        # Each entry being parsed is 32 bytes long.\n",
    "        entry = data[i:i + 32]\n",
    "\n",
    "        # Check if the entry is likely a directory entry based on the ASCII name and extension.\n",
    "        if is_likely_directory_entry(entry):\n",
    "\n",
    "            # Extract the file name and extension from the entry, and store in the dictionary.\n",
    "            # Ignore any encoding errors and strip any whitespace.\n",
    "            file_name = entry[:8].decode('ascii', errors='ignore').strip()\n",
    "            file_ext = entry[8:11].decode('ascii', errors='ignore').strip()\n",
    "\n",
    "            # Store the file name in the dictionary based on the extension.\n",
    "            files[file_ext] = file_name\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "# Define the file extensions we are looking for, represented in bytes.\n",
    "# This will be used to validate the directory entries found in the disk image.\n",
    "common_extensions = [b'JPG', b'PNG', b'GIF', b'AVI', b'PDF']\n",
    "\n",
    "# Find the directory entries in the disk image data, and populate a dictionary with the file names.\n",
    "file_names = find_directory_entries(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define File Signatures, and Trailers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file signatures for the files to be recovered.\n",
    "file_signatures = {\n",
    "    'PDF': b'%PDF',\n",
    "    'GIF': b'GIF89a', # GIF87a not found, so using GIF89a.\n",
    "    'JPG': b'\\xFF\\xD8', # Already in Hex.\n",
    "    'AVI': b'RIFF', \n",
    "    'PNG': b'\\x89PNG\\r\\n\\x1a\\n',\n",
    "    \n",
    "}\n",
    "\n",
    "# Define the end of file signatures for the files to be recovered.\n",
    "file_end = {\n",
    "    'PDF': b'%%EOF',\n",
    "    'GIF': b'\\x00\\x3B', \n",
    "    'JPG': b'\\xFF\\xD9',\n",
    "    'AVI': b'', # AVI files are based on size, so no end signature.\n",
    "    'PNG': b'IEND',\n",
    "}\n",
    "\n",
    "# list to store the names of the files recovered.\n",
    "files = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate and Recover the files based on signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the file signatures and find the files in the data.\n",
    "for sig_name, sig_bytes in file_signatures.items():\n",
    "\n",
    "    print(f\"Searching for file signature '{sig_name}'...\")\n",
    "    \n",
    "    # Find the file signature in the data\n",
    "    start = data.find(sig_bytes)\n",
    "\n",
    "    # If the signature is not found, print a message and continue to the next signature.\n",
    "    if start == -1:\n",
    "        print(f\"File signature '{sig_name}' not found.\")\n",
    "    else:\n",
    "        print(f\"File signature '{sig_name}' found at offset {start}.\")\n",
    "        \n",
    "        # Default the end of the file to -1, in case it is not found.\n",
    "        end = -1\n",
    "\n",
    "        # If the file is an AVI file, calculate the end based on the size in the header.\n",
    "        if sig_name == 'AVI':\n",
    "\n",
    "            # Offset for the 4-byte size located after \"RIFF\".\n",
    "            size_offset = start + 4  \n",
    "            avi_size_bytes = data[size_offset:size_offset + 4]\n",
    "            avi_size = int.from_bytes(avi_size_bytes, byteorder='little')\n",
    "\n",
    "            # Calculate the end of the AVI file based on this size.\n",
    "            # Add 8 for the \"RIFF\" and size fields.\n",
    "            end = start + avi_size + 8  \n",
    "\n",
    "            print(f\"AVI file size (from header): {avi_size} bytes.\")\n",
    "            print(f\"End of file calculated at offset {end}.\")\n",
    "        else:\n",
    "\n",
    "            # Find the end of the file signature in the data, if not an AVI file.\n",
    "            if file_end[sig_name]:\n",
    "\n",
    "                # Locate the end of the file signature in the data following the file signature.\n",
    "                end = data.find(file_end[sig_name], start)\n",
    "\n",
    "                # If the end of the file signature is found, update the end offset to encapsulate the file.\n",
    "                end += len(file_end[sig_name])\n",
    "                print(f\"End of file signature '{sig_name}' found at offset {end}.\")\n",
    "        \n",
    "            else:\n",
    "                print(f\"End of file signature '{sig_name}' not found.\")\n",
    "                continue\n",
    "\n",
    "        # Write the file to a new file, add the name to the files list.\n",
    "        with open(f'Project-3/recovered-files/{file_names[sig_name]}.{sig_name.lower()}', 'wb') as output_file:\n",
    "            output_file.write(data[start:end])\n",
    "        files.append(f'{file_names[sig_name]}.{sig_name.lower()}')\n",
    "\n",
    "\n",
    "        print(f\"File '{file_names[sig_name]}.{sig_name.lower()}' has been saved.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hash the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library needed for hashing the files.\n",
    "import hashlib\n",
    "\n",
    "# Function to generate a SHA-256 hash for a file\n",
    "def generate_sha256_hash(file_path):\n",
    "\n",
    "    # Create a SHA-256 hash object\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    \n",
    "    # Open the file in binary mode (rb) and read in chunks\n",
    "    with open(file_path, 'rb') as file:\n",
    "        for chunk in iter(lambda: file.read(4096), b\"\"):  \n",
    "            sha256_hash.update(chunk)\n",
    "    \n",
    "    # Return the hexadecimal digest of the hash\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "# Generate SHA-256 hashes for the recovered files.\n",
    "hashes = {}\n",
    "for name in files:\n",
    "    file_path = f'Project-3/recovered-files/{name}'\n",
    "    hash_value = generate_sha256_hash(file_path)\n",
    "    hashes[name] = hash_value\n",
    "    print(f\"{name}: {hash_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
